# -*- coding: utf-8 -*-
"""
population_analysis.py

This script performs a population-level analysis of pharyngeal pumping data.
It reads summary and feature CSV files generated by 'detect_pharynx_waves.py'
to explore and visualize differences between experimental groups (e.g., strains)
across different time points (e.g., days).

Assumptions:
- A main data directory (DATA_DIR) contains all relevant CSV files.
- Summary CSV files are named following the pattern: '<strain> dia <day>_summary.csv'.
- Feature CSV files are named following the pattern: '<strain> dia <day>_features_full.csv'.
"""

import os
import glob
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
import umap.umap_ as umap
from scipy import stats
import re

# Define a list of markers for plotting different strains in UMAP visualizations.
MARKERS = ['o', 's', '^', 'P', 'X', 'D', 'v', '<', '>', '*']

# Configure global plotting styles using seaborn.
sns.set(style="whitegrid", font_scale=1.1)
plt.rcParams['figure.figsize'] = (10, 6)

# Specify the directory containing the dataset CSV files.
# This path must be updated to the location of the generated CSVs.
DATA_DIR = '/Users/ignaciomgb/Documents/OpenEphysAnalisis2025/AnlisisDatosFer/Datos Fer/Dia 1/CSVs'

def extract_strain_day(filename):
    """
    Extracts strain and day information from a filename using regular expressions.

    Args:
        filename (str): The base name of the file.

    Returns:
        tuple: A tuple containing the extracted strain (str) and day (int).
               Returns (None, None) if the pattern is not found.
    """
    base = os.path.basename(filename).replace("_summary.csv", "").replace("_features_full.csv", "")
    pattern = r"(.*?)\s*dia\s*(\d+)"
    match = re.search(pattern, base, re.IGNORECASE)

    if match:
        strain = match.group(1).strip()
        day = int(match.group(2))
        return strain, day
    else:
        print(f"Warning: Could not extract strain/day from: {base}")
        return None, None

def load_summary_data():
    """
    Loads and aggregates all '*_summary.csv' files from the DATA_DIR.
    This function transforms data from a long format (one metric per row)
    to a wide format (one experimental unit per row).
    
    Returns:
        pd.DataFrame: A DataFrame containing the aggregated summary data,
                      or an empty DataFrame if no data could be loaded.
    """
    summary_files = glob.glob(os.path.join(DATA_DIR, "*_summary.csv"))
    all_summary_data = []

    for fp in summary_files:
        strain, day = extract_strain_day(fp)
        if strain is None or day is None:
            continue

        try:
            df = pd.read_csv(fp)
            if 'metric' in df.columns and 'mean' in df.columns:
                row_data = {'strain': strain, 'day': day}
                for _, row in df.iterrows():
                    metric = row['metric']
                    if pd.notna(row.get('mean')):
                        row_data[metric] = row['mean']
                    if pd.notna(row.get('stderr')):
                        row_data[f"{metric}_sem"] = row['stderr']
                    if pd.notna(row.get('std')):
                        row_data[f"{metric}_std"] = row['std']
                all_summary_data.append(row_data)
            else:
                print(f"Warning: Incorrect format in {fp}: 'metric' and 'mean' columns not found.")
        except Exception as e:
            print(f"Error: Failed to process {fp}: {str(e)}")

    if all_summary_data:
        return pd.DataFrame(all_summary_data)
    else:
        print("Error: No summary data could be loaded.")
        return pd.DataFrame()

def load_features_full():
    """
    Loads and concatenates all '*_features_full.csv' files from the DATA_DIR.
    It ensures that 'strain' and 'day' columns are present in the final DataFrame.

    Returns:
        pd.DataFrame: A DataFrame containing the concatenated feature data,
                      or an empty DataFrame if loading fails.
    """
    features_files = glob.glob(os.path.join(DATA_DIR, "*_features_full.csv"))
    feature_list = []

    for fp in features_files:
        try:
            df = pd.read_csv(fp)
            if 'strain' not in df.columns or 'day' not in df.columns:
                strain, day = extract_strain_day(fp)
                if strain is not None and day is not None:
                    df['strain'] = strain
                    df['day'] = day
            feature_list.append(df)
        except Exception as e:
            print(f"Error: Failed to process {fp}: {str(e)}")

    if feature_list:
        return pd.concat(feature_list, ignore_index=True)
    else:
        print("Error: No full feature data could be loaded.")
        return pd.DataFrame()

def plot_summary_data(df_summary_all):
    """
    Generates and saves a series of plots from the summary data to compare
    strains across different days.

    Args:
        df_summary_all (pd.DataFrame): The DataFrame containing aggregated summary data.
    """
    if df_summary_all.empty:
        print("Notice: No summary data available for plotting.")
        return

    exclude_cols = ['strain', 'day']
    metrics = [col for col in df_summary_all.columns if not col.endswith(('_sem', '_std')) and col not in exclude_cols]
    strain_order = ['N2', 'ATM1', 'CZ26389', 'DM']

    print(f"Available metrics for summary plotting: {metrics}")

    for metric in metrics:
        sem_col = f"{metric}_sem" if f"{metric}_sem" in df_summary_all.columns else None

        plt.figure(figsize=(10, 6))
        if sem_col:
            pivot_mean = df_summary_all.pivot(index='day', columns='strain', values=metric)
            pivot_sem = df_summary_all.pivot(index='day', columns='strain', values=sem_col)
            pivot_mean = pivot_mean.reindex(columns=strain_order)
            pivot_sem = pivot_sem.reindex(columns=strain_order)
            
            ax = pivot_mean.plot(kind='bar', yerr=pivot_sem, capsize=4, figsize=(10, 6),
                                 color=sns.color_palette('pastel', n_colors=len(pivot_mean.columns)))
            ax.set_title(f"{metric} by Strain and Day")
            ax.set_xlabel("Day (Age)")
            ax.set_ylabel(metric)
            ax.legend(title="Strain", bbox_to_anchor=(1.05, 1), loc='upper left')
        else:
            sns.violinplot(data=df_summary_all, x='strain', y=metric, order=strain_order,
                           inner='quartile', scale='width', palette='Set2')
            plt.title(f"{metric} by Strain")
            plt.xlabel("Strain")
            plt.ylabel(metric)

        plt.tight_layout()
        plt.savefig(os.path.join(DATA_DIR, f"summary_{metric}.png"), dpi=300)
        plt.show()

    metrics_over_time = ['total_events', 'mean_freq', 'cv_freq', 'cv2', 'mean_duration_ms', 'events_per_min']
    for metric in metrics_over_time:
        if metric in df_summary_all.columns:
            days_sorted = [3, 6, 12]
            df_tc = df_summary_all[df_summary_all['day'].isin(days_sorted)]
            
            pivot_mean = df_tc.pivot_table(index='day', columns='strain', values=metric, aggfunc='mean').reindex(index=days_sorted, columns=strain_order)
            sem_col = f"{metric}_sem"
            pivot_sem = df_tc.pivot_table(index='day', columns='strain', values=sem_col if sem_col in df_tc.columns else metric,
                                          aggfunc='mean' if sem_col in df_tc.columns else lambda x: x.sem()).reindex(index=days_sorted, columns=strain_order)

            x = np.arange(len(days_sorted))
            plt.figure(figsize=(8, 5))
            ax = plt.gca()
            colors = sns.color_palette('tab10', n_colors=len(strain_order))

            for i, strain in enumerate(strain_order):
                y = pivot_mean[strain].values
                yerr = pivot_sem[strain].values
                ax.errorbar(x, y, yerr=yerr, marker='o', markersize=8, markeredgecolor='black', linestyle='-',
                            linewidth=2, label=strain, capsize=6, color=colors[i], ecolor=colors[i], elinewidth=2)

            ax.set_xticks(x)
            ax.set_xticklabels(days_sorted)
            ax.set_xlim(-0.5, len(days_sorted) - 0.5)
            plt.title(f"{metric} vs. Day by Strain")
            plt.xlabel("Day (Age)")
            plt.ylabel(metric)
            plt.legend(title="Strain", bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.tight_layout()
            plt.savefig(os.path.join(DATA_DIR, f"timecourse_{metric}.png"), dpi=300)
            plt.show()

def plot_features(df_features_all):
    """
    Generates and saves a variety of plots from the full features DataFrame
    to visualize distributions and relationships between metrics.

    Args:
        df_features_all (pd.DataFrame): The DataFrame with detailed feature data.
    """
    if df_features_all.empty:
        print("Notice: No full feature data available for plotting.")
        return

    strain_order = ['N2', 'ATM1', 'CZ26389', 'DM']
    
    # Generate violin plots with individual data points overlaid.
    for metric in ['burst_index', 'trend_slope', 'dom_peak_ls']:
        if metric in df_features_all.columns:
            plt.figure(figsize=(10, 6))
            ax = sns.violinplot(data=df_features_all, x='strain', y=metric, hue='day', order=strain_order, inner=None, palette='Set2')
            sns.stripplot(data=df_features_all, x='strain', y=metric, hue='day', order=strain_order, dodge=True,
                          jitter=0.25, size=6, alpha=0.8, palette='dark', ax=ax, linewidth=0)
            handles, labels = ax.get_legend_handles_labels()
            unique_days = len(df_features_all['day'].unique())
            ax.legend(handles[0:unique_days], labels[0:unique_days], title='Day', bbox_to_anchor=(1.05, 1), loc='upper left')
            ax.set_title(f"{metric} by Strain and Day (with individual points)")
            ax.set_xlabel("Strain")
            ax.set_ylabel(metric)
            plt.tight_layout()
            plt.savefig(os.path.join(DATA_DIR, f"{metric}_violin_with_points.png"), dpi=300)
            plt.show()

    # Perform statistical comparisons and generate additional plots.
    stats_results = []
    exclude_cols = ['file', 'strain', 'day', 'UMAP1', 'UMAP2']
    metrics = [col for col in df_features_all.columns if col not in exclude_cols]

    for metric in ['mean_freq', 'cv_freq', 'mean_duration_ms', 'cv2']:
        if metric in df_features_all.columns:
            plt.figure(figsize=(12, 6))
            sns.violinplot(data=df_features_all, x='strain', y=metric, hue='day', inner='quartile',
                           split=False, palette='Set2', order=strain_order)
            plt.title(f"Distribution of {metric} by Strain and Day")
            plt.xlabel("Strain")
            plt.ylabel(metric)
            plt.legend(title="Day", bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.tight_layout()
            plt.savefig(os.path.join(DATA_DIR, f"violin_{metric}.png"), dpi=300)
            plt.show()

    key_pairs = [('mean_freq', 'cv_freq'), ('mean_freq', 'cv2'), ('sd1', 'sd2'), ('ap_en', 'samp_en')]
    for x_col, y_col in key_pairs:
        if x_col in df_features_all.columns and y_col in df_features_all.columns:
            plt.figure(figsize=(9, 7))
            sns.scatterplot(data=df_features_all, x=x_col, y=y_col, hue='strain', style='day', s=80, alpha=0.7, palette='tab10')
            plt.title(f"Relationship between {y_col} and {x_col}")
            plt.xlabel(x_col)
            plt.ylabel(y_col)
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.tight_layout()
            plt.savefig(os.path.join(DATA_DIR, f"scatter_{x_col}_vs_{y_col}.png"), dpi=300)
            plt.show()

    # UMAP analysis
    num_cols = df_features_all.select_dtypes(include=[np.number]).columns
    fea_cols = [col for col in num_cols if col not in exclude_cols]
    if len(fea_cols) >= 2:
        X = df_features_all[fea_cols].values
        X_imp = SimpleImputer(strategy='mean').fit_transform(X)
        X_scaled = StandardScaler().fit_transform(X_imp)

        for n_neighbors in [5, 15, 30]:
            for min_dist in [0.1, 0.5]:
                try:
                    reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=2, random_state=42)
                    embedding = reducer.fit_transform(X_scaled)
                    df_plot = df_features_all.copy()
                    df_plot['UMAP1'], df_plot['UMAP2'] = embedding[:, 0], embedding[:, 1]

                    fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharex=True, sharey=True)
                    sns.scatterplot(data=df_plot, x='UMAP1', y='UMAP2', hue='strain', style='day', s=80, alpha=0.7, palette='tab10', ax=axes[0])
                    axes[0].set_title(f"UMAP by Strain (n={n_neighbors}, d={min_dist})")
                    axes[0].set_xlabel("UMAP 1")
                    axes[0].set_ylabel("UMAP 2")
                    sns.scatterplot(data=df_plot, x='UMAP1', y='UMAP2', hue='day', style='strain', s=80, alpha=0.7, palette='viridis', ax=axes[1])
                    axes[1].set_title(f"UMAP by Day (n={n_neighbors}, d={min_dist})")
                    axes[1].set_xlabel("UMAP 1")
                    plt.tight_layout()
                    plt.savefig(os.path.join(DATA_DIR, f"umap_n{n_neighbors}_d{min_dist}.png"), dpi=300)
                    plt.show()
                except Exception as e:
                    print(f"Warning: UMAP failed for n={n_neighbors}, d={min_dist}: {str(e)}")

    # Statistical comparisons
    unique_days = sorted(df_features_all['day'].unique())
    for day in unique_days:
        df_day = df_features_all[df_features_all['day'] == day]
        strains = df_day['strain'].unique()
        if len(strains) >= 2:
            print(f"\nStatistical Analysis for Day {day}:")
            for metric in ['mean_freq', 'cv_freq', 'cv2', 'mean_duration_ms']:
                if metric in df_features_all.columns:
                    print(f"\n-- Metric: {metric} --")
                    try:
                        groups = [df_day[df_day['strain'] == s][metric].dropna() for s in strains]
                        valid_groups = [g for g in groups if len(g) > 0]
                        if len(valid_groups) >= 2:
                            f_stat, p_val = stats.f_oneway(*valid_groups)
                            stats_results.append({'day': day, 'metric': metric, 'test': 'ANOVA', 'statistic': f_stat, 'p_value': p_val})
                            print(f"  ANOVA: F={f_stat:.3f}, p={p_val:.4f}{' (*)' if p_val < 0.05 else ''}")
                            if p_val < 0.05:
                                print("  Post-hoc (Fisher's LSD):")
                                for i, s1 in enumerate(strains):
                                    for s2 in strains[i+1:]:
                                        v1 = df_day[df_day['strain'] == s1][metric].dropna()
                                        v2 = df_day[df_day['strain'] == s2][metric].dropna()
                                        if len(v1) > 0 and len(v2) > 0:
                                            t_stat, p_post = stats.ttest_ind(v1, v2, equal_var=False, nan_policy='omit')
                                            stars = '***' if p_post < 0.001 else '**' if p_post < 0.01 else '*' if p_post < 0.05 else ''
                                            stats_results.append({'day': day, 'metric': metric, 'test': "Fisher's LSD", 'group1': s1, 'group2': s2, 'statistic': t_stat, 'p_value': p_post, 'significance': stars})
                                            print(f"    {s1} vs {s2}: p={p_post:.4f} {stars}")
                    except Exception as e:
                        print(f"  Warning: ANOVA for {metric} failed: {str(e)}")

    if stats_results:
        df_stats = pd.DataFrame(stats_results)
        stats_csv = os.path.join(DATA_DIR, 'statistics_results.csv')
        df_stats.to_csv(stats_csv, index=False)
        print(f"\nSaved statistical results to: {stats_csv}")

def export_concatenated_data(df_summary, df_features, output_dir):
    """
    Exports the master concatenated DataFrames to CSV files.

    Args:
        df_summary (pd.DataFrame): The concatenated summary DataFrame.
        df_features (pd.DataFrame): The concatenated features DataFrame.
        output_dir (str): The directory to save the files in.
    """
    os.makedirs(output_dir, exist_ok=True)
    if not df_summary.empty:
        df_summary.to_csv(os.path.join(output_dir, "ALL_summary_concatenated.csv"), index=False)
        print(f"Successfully saved: {os.path.join(output_dir, 'ALL_summary_concatenated.csv')}")
    if not df_features.empty:
        df_features.to_csv(os.path.join(output_dir, "ALL_features_full_concatenated.csv"), index=False)
        print(f"Successfully saved: {os.path.join(output_dir, 'ALL_features_full_concatenated.csv')}")

def main():
    """
    Main execution function to run the full population analysis pipeline.
    """
    print("\n--- PHARYNX WAVES POPULATION ANALYSIS ---")
    print(f"Data directory: {DATA_DIR}")
    
    print("\nLoading summary files...")
    df_summary_all = load_summary_data()
    
    print("\nLoading full feature files...")
    df_features_all = load_features_full()

    days_of_interest = [3, 6, 12]
    df_summary_all = df_summary_all[df_summary_all['day'].isin(days_of_interest)].reset_index(drop=True)
    df_features_all = df_features_all[df_features_all['day'].isin(days_of_interest)].reset_index(drop=True)

    if not df_summary_all.empty:
        print(f"\nSummary data loaded: {len(df_summary_all)} records.")
        print(f"  Strains: {sorted(df_summary_all['strain'].unique())}")
        print(f"  Days: {sorted(df_summary_all['day'].unique())}")
    
    if not df_features_all.empty:
        print(f"\nFeature data loaded: {len(df_features_all)} records.")
        print(f"  Strains: {sorted(df_features_all['strain'].unique())}")
        print(f"  Days: {sorted(df_features_all['day'].unique())}")
    
    print("\nGenerating summary plots...")
    plot_summary_data(df_summary_all)
    
    print("\nGenerating feature plots...")
    plot_features(df_features_all)
    
    print("\nExporting concatenated data...")
    export_concatenated_data(df_summary_all, df_features_all, DATA_DIR)
    
    print("\n--- Analysis complete. ---")

if __name__ == "__main__":
    main()
